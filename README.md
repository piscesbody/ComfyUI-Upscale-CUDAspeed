# ComfyUI Upscale CUDAspeed

基于CUDA加速的高性能图像&视频放大插件，专为ComfyUI设计。

## 作者的话

我一般用于1280x720 161f视频放大，使用RealESRGAN_x2plus.pth模型，参数设置如下：
use_autocast: 启用
precision: fp16
tile_size: 1280（视频最长边）
overlap: 8（视频放大无所谓，最小值即可）
enable_compile: 启用（编译第一次运行需要30秒左右的时间，但是速度提升80%，批量处理建议开启。）
optimization_level: 优化级别speed

<img width="429" height="358" alt="image" src="https://github.com/user-attachments/assets/fc74de34-5333-4bd8-b1d6-9c413deb7d21" />


目前无法解决编译时长问题，ai写的代码，deepseek，GPT-5，claude轮番上阵，认知不够无法解决。望大佬指点。

## 功能特性

### 🚀 高性能CUDA加速
- 利用PyTorch的`torch.compile`进行模型编译优化
- 动态尺寸编译，避免每次尺寸变化都重新编译
- 智能内存管理，自动优化显存使用

### 🎯 智能参数优化
- **自动瓦片大小计算**：根据图像尺寸智能调整瓦片大小
- **重叠区域优化**：自动计算最优重叠区域，避免接缝问题
- **多精度支持**：支持fp16、fp32、bf16精度模式
- **自动混合精度**：启用自动混合精度提升性能

### ⚙️ 灵活的配置选项
- **优化级别**：平衡模式、速度优先、内存优先
- **模型编译**：可选的模型编译功能
- **批处理支持**：支持批量处理提升效率
- **瓦片处理**：可自定义瓦片大小和重叠区域

## 安装方法

1. 将本插件文件夹复制到ComfyUI的`custom_nodes`目录
2. 重启ComfyUI
3. 在节点菜单中找到"🚀 Upscale Image CUDAspeed"节点

## 使用方法

### 基本使用流程

1. **加载放大模型**：
   - 使用`UpscaleModelLoader`节点加载放大模型
   - 支持所有ComfyUI兼容的放大模型

2. **配置放大参数**：
   - 连接图像输入和放大模型
   - 调整以下参数：
     - `use_autocast`: 启用/禁用自动混合精度
     - `precision`: 选择计算精度（auto/fp16/fp32/bf16）
     - `tile_size`: 瓦片大小（0为自动计算）
     - `overlap`: 重叠区域大小（0为自动计算）
     - `enable_compile`: 启用/禁用模型编译
     - `optimization_level`: 优化级别（balanced/speed/memory）

### 参数说明

#### 精度设置
- **auto**: 自动选择最优精度
- **fp16**: 半精度浮点数，性能最佳
- **fp32**: 单精度浮点数，精度最高
- **bf16**: 脑浮点数，平衡精度和性能

#### 优化级别
- **balanced**: 平衡性能和内存使用
- **speed**: 速度优先，使用更大的瓦片
- **memory**: 内存优先，使用更小的瓦片

#### 瓦片处理
- **tile_size**: 处理图像时使用的瓦片大小
  - 0: 自动计算最优大小
  - 建议值: 256-1024
- **overlap**: 瓦片之间的重叠区域
  - 0: 自动计算最优重叠
  - 建议值: 8-64

## 性能优化建议

### 硬件要求
- **GPU**: NVIDIA显卡，支持CUDA
- **显存**: 建议8GB以上
- **驱动**: 最新NVIDIA驱动

### 性能调优
1. **大显存显卡**：启用模型编译，使用速度优先模式
2. **小显存显卡**：使用内存优先模式，减小瓦片大小
3. **高质量需求**：使用fp32精度，禁用自动混合精度
4. **批量处理**：启用批处理功能提升效率

### 内存管理
- 插件会自动管理显存使用
- 支持动态瓦片大小调整
- 智能输出设备选择（GPU/CPU）

## 技术特点

### 模型编译优化
- 使用PyTorch的`torch.compile`进行即时编译
- 动态尺寸支持，避免重复编译
- 运行时缓存，提升重复使用效率

### 异步处理
- 数据预处理和模型编译并行执行
- 多CUDA流优化，提升GPU利用率
- 非阻塞数据传输

### 智能后处理
- 自动检测和修复编译模型输出问题
- 数值范围归一化
- 异常值处理

## 故障排除

### 常见问题

**Q: 编译失败怎么办？**
A: 禁用`enable_compile`选项，使用普通模式

**Q: 显存不足怎么办？**
A: 减小`tile_size`，启用`optimization_level`为"memory"

**Q: 输出图像发白？**
A: 这是编译模型的常见问题，插件会自动进行后处理修复

**Q: 处理速度慢？**
A: 启用`enable_compile`，使用`optimization_level`为"speed"

### 日志信息
插件会输出详细的处理日志，包括：
- 设备信息
- 内存使用情况
- 处理时间统计
- 性能优化建议

## 版本信息

- **当前版本**: 1.0.0
- **兼容性**: ComfyUI 最新版本
- **依赖**: PyTorch, spandrel, tqdm（可选）

## 贡献

欢迎提交问题和改进建议！

## 许可证

本项目基于MIT许可证开源。
